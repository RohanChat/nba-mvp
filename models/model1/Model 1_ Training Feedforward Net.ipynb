{"cells":[{"cell_type":"code","metadata":{"source_hash":"34a7bf4c","execution_start":1743270744367,"execution_millis":3878,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"1a993dee51694df3a7765f5c49a7ec0d","deepnote_cell_type":"code"},"source":"!python3.11 -m pip install seaborn matplotlib tensorflow scikit-learn numpy","block_group":"f0d390a72c6c43b880105e1d91db3b1d","execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: seaborn in /root/venv/lib/python3.11/site-packages (0.13.2)\nRequirement already satisfied: matplotlib in /root/venv/lib/python3.11/site-packages (3.8.4)\nRequirement already satisfied: tensorflow in /root/venv/lib/python3.11/site-packages (2.15.1)\nRequirement already satisfied: scikit-learn in /root/venv/lib/python3.11/site-packages (1.3.2)\nRequirement already satisfied: numpy in /root/venv/lib/python3.11/site-packages (1.26.4)\nRequirement already satisfied: pandas>=1.2 in /root/venv/lib/python3.11/site-packages (from seaborn) (2.1.4)\nRequirement already satisfied: contourpy>=1.0.1 in /root/venv/lib/python3.11/site-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /root/venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /root/venv/lib/python3.11/site-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /root/venv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /root/venv/lib/python3.11/site-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=8 in /root/venv/lib/python3.11/site-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /root/venv/lib/python3.11/site-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /root/venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: absl-py>=1.0.0 in /root/venv/lib/python3.11/site-packages (from tensorflow) (2.1.0)\nRequirement already satisfied: astunparse>=1.6.0 in /root/venv/lib/python3.11/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /root/venv/lib/python3.11/site-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /root/venv/lib/python3.11/site-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /root/venv/lib/python3.11/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /root/venv/lib/python3.11/site-packages (from tensorflow) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /root/venv/lib/python3.11/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /root/venv/lib/python3.11/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /root/venv/lib/python3.11/site-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /root/venv/lib/python3.11/site-packages (from tensorflow) (4.25.6)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.11/site-packages (from tensorflow) (65.5.0)\nRequirement already satisfied: six>=1.12.0 in /root/venv/lib/python3.11/site-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /root/venv/lib/python3.11/site-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /root/venv/lib/python3.11/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /root/venv/lib/python3.11/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /root/venv/lib/python3.11/site-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /root/venv/lib/python3.11/site-packages (from tensorflow) (1.70.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /root/venv/lib/python3.11/site-packages (from tensorflow) (2.15.2)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /root/venv/lib/python3.11/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /root/venv/lib/python3.11/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: scipy>=1.5.0 in /root/venv/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /root/venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /root/venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: pytz>=2020.1 in /root/venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.1)\nRequirement already satisfied: tzdata>=2022.1 in /root/venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /root/venv/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.38.0)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /root/venv/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\nRequirement already satisfied: markdown>=2.6.8 in /root/venv/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.7)\nRequirement already satisfied: requests<3,>=2.21.0 in /root/venv/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /root/venv/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /root/venv/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.1.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /root/venv/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.5.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /root/venv/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /root/venv/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /root/venv/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /root/venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /root/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /root/venv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/2c528e75-0481-4a4d-98b4-3a36f9a0d0c0","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"e4b7e98","execution_start":1743270748296,"execution_millis":455,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"290cc15c7cd04b7b985bd22786d437d0","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport time\nimport os\nimport numpy as np\nimport gc\nfrom sklearn.metrics import classification_report, mean_squared_error\nimport psutil","block_group":"e3b08cd82a734afe98249208833a1f2a","execution_count":2,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"721ff0fd","execution_start":1743270748796,"execution_millis":1778,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"c1dc82efebf94a87a77f9d078de682b1","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import EarlyStopping","block_group":"9b7bd2e004384ebb94728c0ff02f7f77","execution_count":3,"outputs":[{"name":"stderr","text":"2025-03-29 17:52:29.058104: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2025-03-29 17:52:29.092590: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-29 17:52:29.092675: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-29 17:52:29.093674: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-03-29 17:52:29.099671: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-03-29 17:52:29.929401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/f5d9c1af-0203-4ae4-bc36-6be6e6e8a5db","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"35f82e48","execution_start":1743270750626,"execution_millis":3082,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"e63df3c873494d079f46dfe866df1e7f","deepnote_cell_type":"code"},"source":"def read_csv_file(file_path):\n    df = pd.read_csv(file_path)\n    return df\n\n# Load the dataset\n# Assuming 'chunked_pbp_with_scores_2022.csv' is in the same directory\n# If the file is in a different directory, provide the full path to the file\ndef group_by_game_id_and_chunk(df):\n    grouped = df.groupby(['game_id', 'time_chunk'])\n    return grouped \n\ndf = read_csv_file('chunked_pbp_with_scores_2022.csv')\ngrouped_df = group_by_game_id_and_chunk(df)\n\n\ndef clean_scores(chunk_df):\n    df = chunk_df.copy()\n    \n    df = df.sort_values('eventnum').reset_index(drop=True)\n        \n    # Initialize previous score and scoremargin\n    prev_score = None\n    prev_scoremargin = None\n    for index, row in enumerate(df.itertuples(index=False)):\n        # print(row.score, row.scoremargin, pd.isna(row.score), pd.isna(row.scoremargin))\n        if row.score == '' or pd.isna(row.score):\n            if prev_score is not None:\n                # print(f\"Using previous score: {prev_score}\")\n                df.at[index, 'score'] = prev_score\n            else:\n                # print(\"Both previous score and current score are None. Setting to default.\")\n                df.at[index, 'score'] = '0 - 0'\n        else:\n            # print(f\"Current score is valid: {row.score}\")\n            prev_score = row.score\n\n        if row.scoremargin == '' or pd.isna(row.scoremargin) or row.scoremargin == 'TIE':\n            if prev_scoremargin is not None:\n                # print(f\"Using previous scoremargin: {prev_scoremargin}\")\n                df.at[index, 'scoremargin'] = prev_scoremargin\n            else:\n                # print(\"Both previous scoremargin and current scoremargin are None. Setting to default.\")\n                df.at[index, 'scoremargin'] = '0'\n        else:\n            # print(f\"Current scoremargin is valid: {row.scoremargin}\")\n            prev_scoremargin = row.scoremargin\n    # print(\"Final scores and score margins after filling:\")\n    # print(df[['score', 'scoremargin']])\n    return df\n\n        \n        \n    # # Replace 'TIE' with 0 and clean numeric scoremargin\n    # df['scoremargin_clean'] = df['scoremargin'].replace({'TIE': '0', '': np.nan})\n    # df['scoremargin_clean'] = pd.to_numeric(df['scoremargin_clean'], errors='coerce')\n\n    # # Forward fill scoremargin\n    # df['scoremargin_filled'] = df['scoremargin_clean'].ffill().fillna(0.0)\n\n    # # Forward fill score (like '2 - 0')\n    # df['score_filled'] = df['score'].ffill().fillna('0 - 0')\n\n    # # Compute margin from score if score exists\n    # def margin_from_score(score_str):\n    #     try:\n    #         home, away = map(int, score_str.strip().split('-'))\n    #         return home - away\n    #     except:\n    #         return np.nan\n\n    # df['margin_from_score'] = df['score_filled'].apply(margin_from_score)\n\n    # # Final fallback: use margin from score if scoremargin was missing\n    # df['scoremargin_final'] = df['scoremargin_clean'].combine_first(df['margin_from_score'])\n    # df['scoremargin_final'] = df['scoremargin_final'].ffill().fillna(0.0)\n\n    # return df[['eventnum', 'score', 'score_filled', 'scoremargin', 'scoremargin_filled', 'scoremargin_final']]\n","block_group":"57109162a68b4caf9d8cbf3ad2a66bc8","execution_count":4,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"f4a16c97","execution_start":1743270753756,"execution_millis":827,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"05a6efde02df4fff956e1f0608c802f3","deepnote_cell_type":"code"},"source":"# Pick one sample group (first one)\nsample_key = list(grouped_df.groups.keys())[0]\nprint(f\"\\nSample key: {sample_key}\")\n\n# Extract the chunk DataFrame\n# For demonstration, we will take the first group as a sample\n\n# Print the number of groups\nchunk_df = grouped_df.get_group(sample_key)\n\ncleaned_scores = clean_scores(chunk_df)\nprint(\"\\nCleaned scores for the sample chunk:\")\nprint(cleaned_scores[\"eventmsgactiontype\"].value_counts())  # Display the count of each event type\nprint(cleaned_scores[['eventnum', 'score', 'scoremargin']])  # Display first 10 rows for brevity","block_group":"66794901289649e583b724a515e30624","execution_count":5,"outputs":[{"name":"stdout","text":"\nSample key: (22100001, 1.0)\n\nCleaned scores for the sample chunk:\neventmsgactiontype\n0      15\n1       4\n79      4\n72      3\n11      2\n2       2\n12      2\n3       2\n52      1\n80      1\n47      1\n5       1\n97      1\n103     1\nName: count, dtype: int64\n    eventnum   score scoremargin\n0          2   0 - 0           0\n1          4   0 - 0           0\n2          7   0 - 0           0\n3          8   0 - 0           0\n4          9   0 - 0           0\n5         11   0 - 0           0\n6         12   0 - 0           0\n7         13   0 - 0           0\n8         14   0 - 0           0\n9         15   0 - 0           0\n10        16   0 - 0           0\n11        18   0 - 0           0\n12        19   0 - 0           0\n13        20   2 - 0          -2\n14        22   2 - 0          -2\n15        23   2 - 0          -2\n16        24   2 - 2          -2\n17        25   2 - 2          -2\n18        26   2 - 2          -2\n19        27   2 - 5           3\n20        29   4 - 5           1\n21        31   4 - 5           1\n22        32   4 - 5           1\n23        33   4 - 5           1\n24        35   4 - 5           1\n25        36   4 - 5           1\n26        37   4 - 5           1\n27        38   4 - 5           1\n28        39   4 - 5           1\n29        40   4 - 7           3\n30        41   4 - 7           3\n31        42   4 - 7           3\n32        43  4 - 10           6\n33        44  4 - 10           6\n34        46  5 - 10           5\n35        47  6 - 10           4\n36        48  6 - 10           4\n37        49  6 - 10           4\n38        50  6 - 10           4\n39        52  6 - 10           4\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/ee22ea34-c5bd-459d-abc2-b8c0e60e0d46","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"ea3971f","execution_start":1743270754637,"execution_millis":0,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"6feeda822e8d441f9e12864b55506e34","deepnote_cell_type":"code"},"source":"\nevent_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\nevent_encoder.fit(df[['eventmsgtype', 'eventmsgactiontype']])","block_group":"1bbb3174972a4c9c84245acc78a89df4","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"OneHotEncoder(handle_unknown='ignore', sparse_output=False)","text/html":"<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/d45cb354-26c9-4b0c-9c1b-0646494a363b","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"42155be7","execution_start":1743270754687,"execution_millis":0,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"ad4dcf26602349d3b46eac6a0a89fa1b","deepnote_cell_type":"code"},"source":"print(event_encoder.categories_)","block_group":"902b29018faf4ddb8a1cff1fa3983761","execution_count":7,"outputs":[{"name":"stdout","text":"[array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 18]), array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  25,  26,  27,\n        28,  29,  30,  33,  35,  36,  37,  39,  40,  41,  42,  43,  44,\n        45,  47,  50,  51,  52,  57,  58,  63,  66,  67,  71,  72,  73,\n        74,  75,  76,  78,  79,  80,  86,  87,  93,  96,  97,  98,  99,\n       100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110])]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/ae9d4933-cec3-4f3a-92ce-1bcba7a320fb","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"84275200","execution_start":1743270754747,"execution_millis":0,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"466126289c2e484a8697a3db7da5d7c9","deepnote_cell_type":"code"},"source":"def parse_score(score_str):\n    try:\n        parts = str(score_str).split(\" - \")\n        return [int(parts[0]), int(parts[1])]\n    except:\n        return [0, 0]\n\ndef parse_scoremargin(margin):\n    if pd.isna(margin) or margin == 'TIE':\n        return 0\n    try:\n        return int(float(margin))\n    except:\n        return 0\n\ndef vectorize_chunk(chunk_df, event_encoder, max_seq_len=100):\n    \"\"\"\n    Vectorizes a chunk_df into a fixed-size 2D numpy array of shape (max_seq_len, feature_dim).\n    Uses:\n      - One-hot encoding for eventmsgtype and eventmsgactiontype\n      - Parsed score and scoremargin\n      - Numeric columns: period, eventnum, game_seconds, pts_home, pts_away, video_available_flag\n    \"\"\"\n    # print(f\"Input parameters are: {chunk_df.shape}, {event_encoder}, {max_seq_len}\")\n    if chunk_df.empty:\n        print(\"Chunk is empty. Returning zero vector.\")\n        return np.zeros((max_seq_len, event_encoder.transform([[0, 0]]).shape[1] + 9))  # 2 from score, 1 from margin, 6 numerics\n\n    # --- One-hot encoding of eventmsgtype + eventmsgactiontype ---\n    # print(f\"Before one-hot encoding, chunk_df has shape: {chunk_df.shape} and {chunk_df[['eventmsgtype', 'eventmsgactiontype']].dropna().shape}\")\n    event_ohe = event_encoder.transform(chunk_df[['eventmsgtype', 'eventmsgactiontype']])\n    # print(f\"One-hot encoded shape: {event_ohe.shape}\")\n    # print(f\"Event OHE sample:\\n{event_ohe[:5]}\")  # Display first 5 rows for debugging\n\n    # --- Score: \"98 - 97\" -> [98, 97] ---\n    # print(f\"Before parsing scores, chunk_df has shape: {chunk_df.shape} and score column:\\n{chunk_df['score']}\")\n    score_matrix = np.array(chunk_df['score'].apply(parse_score).to_list())  # (N, 2)\n    # print(f\"After parsing scores, score_matrix shape: {score_matrix.shape}, sample:\\n{score_matrix[:5]}\")  # Display first 5 rows for debugging\n\n    # --- Scoremargin: 'TIE' or NaN -> 0 ---\n    # print(f\"Before parsing scoremargin, chunk_df has shape: {chunk_df.shape} and scoremargin column:\\n{chunk_df['scoremargin']}\")\n    scoremargin = chunk_df['scoremargin'].apply(parse_scoremargin).astype(float).values.reshape(-1, 1)\n    # print(f\"After parsing scoremargin, scoremargin shape: {scoremargin.shape}, sample:\\n{scoremargin[:5]}\")  # Display first 5 rows for debugging\n\n    # --- Other numerical columns ---\n    numeric_cols = ['period', 'eventnum', 'game_seconds']\n    # print(\"Before extracting numeric columns, chunk_df has shape with numeric columns: \", chunk_df[numeric_cols].shape)   \n    numeric_data = chunk_df[numeric_cols].fillna(0).astype(float).values  # (N, 6)\n    # print(\"After extracting numeric columns, chunk_df has shape with numeric columns: \", chunk_df[numeric_cols].shape)   \n    # --- Combine all features ---\n    full_vector = np.concatenate([event_ohe, score_matrix, scoremargin, numeric_data], axis=1)  # (N, F)\n    # print(f\"Full vector shape after concatenation: {full_vector.shape}\")\n    # print(f\"Full vector sample:\\n{full_vector[:5]}\")  # Display first 5 rows for debugging\n    # --- Pad or truncate to max_seq_len ---\n    seq_len, feature_dim = full_vector.shape\n\n    if seq_len < max_seq_len:\n        pad = np.zeros((max_seq_len - seq_len, feature_dim))\n        full_vector = np.vstack([full_vector, pad])\n    elif seq_len > max_seq_len:\n        full_vector = full_vector[:max_seq_len]\n\n    return full_vector  \n\n\n\n\nchunk_df = clean_scores(grouped_df.get_group(sample_key))\n# print(\"\\nVectorizing chunk..., shape: \", chunk_df.shape)\n# print(\"Columns in chunk_df: \", chunk_df.columns)\nvectorized_chunk = vectorize_chunk(chunk_df, event_encoder)\n# print(\"\\nVectorized chunk shape: \", vectorized_chunk.shape)\n# print(\"Vectorized chunk sample (first 5 rows):\\n\", vectorized_chunk[:5])  # Display first 5 rows for debugging\n# print(\"\\nVectorized chunk:\\n\", vectorized_chunk)\n\nflattened_vector = vectorized_chunk.flatten()\nprint(\"\\nFlattened vector shape: \", flattened_vector.shape)","block_group":"4aaa2f1388574a28af916bf81d814230","execution_count":8,"outputs":[{"name":"stdout","text":"\nFlattened vector shape:  (9600,)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/2727612e-8920-484f-ad12-b016737c345c","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"74a23795","execution_start":1743270754796,"execution_millis":165410,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"6639a5a130d04ed9a0916c93e9aa6e25","deepnote_cell_type":"code"},"source":"from collections import defaultdict\n\ngroup_cache = defaultdict(dict)\nfor (gid, chunk), group in grouped_df:\n    group_cache[gid][chunk] = group\n\nvector_cache = {}\nfor gid in group_cache:\n    for chunk_id, chunk_df in group_cache[gid].items():\n        cleaned = clean_scores(chunk_df)\n        vector_cache[(gid, chunk_id)] = vectorize_chunk(cleaned, event_encoder)\n\nprint(group_cache)\nprint(vector_cache)","block_group":"ebddad3043fd4dd4b40f201c9c7f1624","execution_count":9,"outputs":[{"text":"IOPub data rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_data_rate_limit`.\n\nCurrent values:\nServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/c11b6be4-d8a3-488a-944e-a7a4eaa923ff","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"6a285783","execution_start":1743270920256,"execution_millis":4341,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"a13b36df38274466b8cd1ad33f089425","deepnote_cell_type":"code"},"source":"X = []\ny_cls = []   # For classification (home win/loss)\ny_reg = []   # For regression (score difference)\nchunk_window = 3\nfor game_id, game_df in df.groupby('game_id'):\n        game_df = game_df.sort_values('time_chunk')\n        chunks = sorted(game_df['time_chunk'].unique())\n        if len(chunks) != 13:\n            # this is for something that can't even get final label and have 3 chunk windows\n            continue \n        final_chunk = chunks[-1]\n        final_chunk_df = grouped_df.get_group((game_id, final_chunk))\n        final_chunk_df = clean_scores(final_chunk_df)\n        pts_home = final_chunk_df['pts_home'].iloc[-1]\n        pts_away = final_chunk_df['pts_away'].iloc[-1]\n        final_score = f\"{pts_home} - {pts_away}\"\n        final_margin = pts_home - pts_away\n        cls_label = 1 if final_margin > 0 else 0\n        \n        for i in range(0, len(chunks) - chunk_window):\n            try:\n                chunk_group = []\n                valid_group = True\n                for t in range(i, i + chunk_window):\n                    vector = vector_cache.get((game_id, chunks[t]))\n                    if vector is None:\n                        valid_group = False \n                        break\n                    chunk_group.append(vector)\n            except KeyError:\n                continue\n            if not valid_group:\n                continue   \n            chunk_stack = np.stack(chunk_group)\n            chunk_flat = chunk_stack.flatten()\n            X.append(chunk_flat)\n            y_cls.append(cls_label)\n            y_reg.append(final_margin)\n\nX = np.array(X)\ny_cls = np.array(y_cls)\ny_reg = np.array(y_reg)\n            \nprint(f\"\\nâœ… Created {len(X)} samples.\")\nprint(\"X shape: \", X.shape)\nprint(\"y_cls shape: \", y_cls.shape)\nprint(\"y_reg shape: \", y_reg.shape)","block_group":"d829f4ea78c442c2af34671d0a656eaa","execution_count":10,"outputs":[{"name":"stdout","text":"\nâœ… Created 11380 samples.\nX shape:  (11380, 28800)\ny_cls shape:  (11380,)\ny_reg shape:  (11380,)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/04f237f5-987c-4716-8aa9-ee2ec7adee31","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"5e2d30bc","execution_start":1743270924646,"execution_millis":1,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"07a822eacaed4c2abefa3c7020427dad","deepnote_cell_type":"code"},"source":"print(X.shape)","block_group":"6a03fdd9e6bb4e67931875314f8c8e7d","execution_count":11,"outputs":[{"name":"stdout","text":"(11380, 28800)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/b4716d08-929b-42c9-9180-4288c0a44aa6","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"603eb00d","execution_start":1743270924696,"execution_millis":109930,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"096ca7b82df74fa182b86368278c4527","deepnote_cell_type":"code"},"source":"\n\n# Scale input first (always before PCA)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Reduce to 300 or 100 dims (try tuning)\npca = PCA(n_components=300)\nX_reduced = pca.fit_transform(X_scaled)\n\nprint(\"New shape:\", X_reduced.shape)  # (10*num_games, 300)","block_group":"3a84251dce494466af15c23e541bb306","execution_count":12,"outputs":[{"name":"stdout","text":"New shape: (11380, 300)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/fc750047-4291-4474-b73c-ab0485690031","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"3621905","execution_start":1743271034676,"execution_millis":1,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"074e9c58fde44e638d3e5f0a8ae59ecf","deepnote_cell_type":"code"},"source":"\n\nX_cls_train, X_cls_val, y_cls_train, y_cls_val = train_test_split(X_reduced, y_cls, test_size=0.2, random_state=42, stratify=y_cls)","block_group":"0c5967b8f0a742eb8cffb2c55a4271b4","execution_count":13,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"a135ade3","execution_start":1743271034726,"execution_millis":1,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"0b4e336b164c4c2496794258968ff045","deepnote_cell_type":"code"},"source":"X_reg_train, X_reg_val, y_reg_train, y_reg_val = train_test_split(X_reduced, y_reg, test_size=0.2, random_state=42, stratify=y_cls)","block_group":"c8c90d4025494bf593ce547e30156595","execution_count":14,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"634aabc5","execution_start":1743271034776,"execution_millis":167,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"19cc2f7196c24d42b41576f8711237e0","deepnote_cell_type":"code"},"source":"tf.keras.backend.clear_session()\ngc.collect()","block_group":"58177456f794487b87c7afee605af38c","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"2345"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/59882894-4d8c-4c4e-8edd-f5dcf29fc2db","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"d7462635","execution_start":1743271068167,"execution_millis":1,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"dc13e6fcde0341c3aadc88f632e3aee8","deepnote_cell_type":"code"},"source":"from tensorflow.keras.callbacks import Callback","block_group":"96958c09e89a4566a87a0d17219b81d6","execution_count":18,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"655ea0b2","execution_start":1743271070853,"execution_millis":2,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"2a18aaada49a435f80f12a96ef03f276","deepnote_cell_type":"code"},"source":"# RAM usage function\ndef print_memory_usage(stage=\"\"):\n    process = psutil.Process(os.getpid())\n    mem_bytes = process.memory_info().rss\n    mem_mb = mem_bytes / (1024 ** 2)\n    print(f\"[{stage}] RAM usage: {mem_mb:.2f} MB\")\n\n# Timing callback to monitor epoch durations\nclass TimingCallback(Callback):\n    def on_train_begin(self, logs=None):\n        self.times = []\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.epoch_time_start = time.time()\n\n    def on_epoch_end(self, epoch, logs=None):\n        epoch_time = time.time() - self.epoch_time_start\n        self.times.append(epoch_time)\n        print(f\"Epoch {epoch+1} took {epoch_time:.2f} seconds\")\n\nprint_memory_usage(\"After imports\")","block_group":"09f7854c5504488c884e0072e82ddb12","execution_count":20,"outputs":[{"name":"stdout","text":"[After imports] RAM usage: 10082.58 MB\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/2ebe6897-35a5-4ce6-b89d-5ef4547b3495","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"da6beb28","execution_start":1743271074106,"execution_millis":278,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"e6747cd130984f1d952ac103ff9ad374","deepnote_cell_type":"code"},"source":"model = Sequential([\n    Dense(256, activation='relu', input_shape=(X_cls_train.shape[1],), kernel_regularizer=l2(0.001)),\n    Dropout(0.3),\n    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid')  # Binary classification\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy', tf.keras.metrics.AUC()]\n)\n\nearly_stop = EarlyStopping(\n    monitor='val_loss',\n    patience=3,\n    restore_best_weights=True\n)\n\ntiming_callback = TimingCallback()\n\nprint_memory_usage(\"After model definition\")","block_group":"4e33dfe2f4c64c28b877aa8d6ddd16b2","execution_count":22,"outputs":[{"name":"stdout","text":"[After model definition] RAM usage: 10085.61 MB\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/3e4243ee-8fa4-41e9-9281-c8a00cb7737f","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"2ceec582","execution_start":1743271077814,"execution_millis":5382,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"39ac8beb917d4ebf9bea2cf59aeeb63d","deepnote_cell_type":"code"},"source":"print(\"\\n--- Starting Training ---\")\ntrain_start = time.time()\n\nhistory = model.fit(\n    X_cls_train, y_cls_train,\n    validation_data=(X_cls_val, y_cls_val),\n    epochs=30,\n    batch_size=32,\n    callbacks=[early_stop, timing_callback],\n    verbose=1\n)\n\ntrain_end = time.time()\nprint(f\"âœ… Total training time: {train_end - train_start:.2f} seconds\")\nprint_memory_usage(\"After training\")","block_group":"e736ad8a507340728a0da391d43a0be8","execution_count":24,"outputs":[{"name":"stdout","text":"\n--- Starting Training ---\nEpoch 1/30\n273/285 [===========================>..] - ETA: 0s - loss: 1.2825 - accuracy: 0.5000 - auc: 0.4923Epoch 1 took 1.40 seconds\n285/285 [==============================] - 1s 3ms/step - loss: 1.2758 - accuracy: 0.4990 - auc: 0.4925 - val_loss: 1.1046 - val_accuracy: 0.5189 - val_auc: 0.4965\nEpoch 2/30\n281/285 [============================>.] - ETA: 0s - loss: 1.0729 - accuracy: 0.5569 - auc: 0.5633Epoch 2 took 0.49 seconds\n285/285 [==============================] - 0s 2ms/step - loss: 1.0723 - accuracy: 0.5570 - auc: 0.5633 - val_loss: 1.0566 - val_accuracy: 0.5277 - val_auc: 0.4806\nEpoch 3/30\n283/285 [============================>.] - ETA: 0s - loss: 0.9947 - accuracy: 0.5799 - auc: 0.6069Epoch 3 took 0.48 seconds\n285/285 [==============================] - 0s 2ms/step - loss: 0.9948 - accuracy: 0.5792 - auc: 0.6065 - val_loss: 1.0024 - val_accuracy: 0.5246 - val_auc: 0.5043\nEpoch 4/30\n285/285 [==============================] - ETA: 0s - loss: 0.9333 - accuracy: 0.6147 - auc: 0.6496Epoch 4 took 0.48 seconds\n285/285 [==============================] - 0s 2ms/step - loss: 0.9333 - accuracy: 0.6147 - auc: 0.6496 - val_loss: 0.9699 - val_accuracy: 0.5290 - val_auc: 0.4938\nEpoch 5/30\n282/285 [============================>.] - ETA: 0s - loss: 0.8838 - accuracy: 0.6262 - auc: 0.6745Epoch 5 took 0.49 seconds\n285/285 [==============================] - 0s 2ms/step - loss: 0.8843 - accuracy: 0.6260 - auc: 0.6741 - val_loss: 0.9551 - val_accuracy: 0.5026 - val_auc: 0.5010\nEpoch 6/30\n281/285 [============================>.] - ETA: 0s - loss: 0.8503 - accuracy: 0.6408 - auc: 0.6923Epoch 6 took 0.49 seconds\n285/285 [==============================] - 0s 2ms/step - loss: 0.8502 - accuracy: 0.6410 - auc: 0.6922 - val_loss: 0.9259 - val_accuracy: 0.5145 - val_auc: 0.5072\nEpoch 7/30\n283/285 [============================>.] - ETA: 0s - loss: 0.8121 - accuracy: 0.6628 - auc: 0.7217Epoch 7 took 0.49 seconds\n285/285 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.6628 - auc: 0.7215 - val_loss: 0.9354 - val_accuracy: 0.4859 - val_auc: 0.4901\nEpoch 8/30\n280/285 [============================>.] - ETA: 0s - loss: 0.7872 - accuracy: 0.6725 - auc: 0.7384Epoch 8 took 0.49 seconds\n285/285 [==============================] - 0s 2ms/step - loss: 0.7874 - accuracy: 0.6731 - auc: 0.7380 - val_loss: 0.9401 - val_accuracy: 0.5009 - val_auc: 0.4780\nEpoch 9/30\n251/285 [=========================>....] - ETA: 0s - loss: 0.7618 - accuracy: 0.6956 - auc: 0.7650Epoch 9 took 0.49 seconds\n285/285 [==============================] - 0s 2ms/step - loss: 0.7650 - accuracy: 0.6921 - auc: 0.7610 - val_loss: 0.9446 - val_accuracy: 0.5110 - val_auc: 0.4979\nâœ… Total training time: 5.38 seconds\n[After training] RAM usage: 7796.39 MB\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/591a75b4-58bf-44b7-923a-7cef1638f44a","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"9d361f7e","execution_start":1743271087804,"execution_millis":101,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"b987d2514a404cb1ba7ae007dad42741","deepnote_cell_type":"code"},"source":"print(\"\\n--- Evaluating Model ---\")\neval_start = time.time()\n\nloss, acc, auc = model.evaluate(X_cls_val, y_cls_val, verbose=0)\nprint(f\"ðŸ“ˆ Val Accuracy: {acc:.4f} | Val AUC: {auc:.4f}\")\n\neval_end = time.time()\nprint(f\"âœ… Evaluation time: {eval_end - eval_start:.2f} seconds\")\n","block_group":"c38b1467e5f740258dd69f15bfd67a35","execution_count":26,"outputs":[{"name":"stdout","text":"\n--- Evaluating Model ---\nðŸ“ˆ Val Accuracy: 0.5145 | Val AUC: 0.5072\nâœ… Evaluation time: 0.10 seconds\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/1643998b-c49a-49ba-adaf-f4d30c5d6a84","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"6824c582","execution_start":1743271090301,"execution_millis":173,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"deac0cdf8d1a4bd99104a2d10ed56425","deepnote_cell_type":"code"},"source":"print(\"\\n--- Predicting ---\")\npred_start = time.time()\n\ny_pred = (model.predict(X_cls_val, verbose=0) > 0.5).astype(int)\n\npred_end = time.time()\nprint(f\"âœ… Prediction time: {pred_end - pred_start:.2f} seconds\")\nprint_memory_usage(\"After evaluation\")\n\n\n# === Classification Report ===\nprint(\"\\n--- Classification Report ---\")\nreport_start = time.time()\n\nprint(classification_report(y_cls_val, y_pred))\n\nreport_end = time.time()\nprint(f\"âœ… Classification report time: {report_end - report_start:.2f} seconds\")\nprint_memory_usage(\"After classification report\")","block_group":"140e2081343d49d8b9cbecdceb347c97","execution_count":28,"outputs":[{"name":"stdout","text":"\n--- Predicting ---\nâœ… Prediction time: 0.17 seconds\n[After evaluation] RAM usage: 7809.93 MB\n\n--- Classification Report ---\n              precision    recall  f1-score   support\n\n           0       0.54      0.66      0.60      1234\n           1       0.46      0.34      0.39      1042\n\n    accuracy                           0.51      2276\n   macro avg       0.50      0.50      0.49      2276\nweighted avg       0.50      0.51      0.50      2276\n\nâœ… Classification report time: 0.01 seconds\n[After classification report] RAM usage: 7809.93 MB\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/01df29da-6448-4479-a8fb-2d8e4162b287","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"7d7d092d","execution_start":1743271168836,"execution_millis":1,"execution_context_id":"ff3eed6d-cd05-4b14-9922-d3dfd61bd045","cell_id":"3c582219450f4c24acb5b706dc995c7b","deepnote_cell_type":"code"},"source":"weights, biases = model.layers[0].get_weights()\nprint(\"First Dense Layer Weights Shape:\", weights.shape)\nprint(\"First Dense Layer Biases Shape:\", biases.shape)\n","block_group":"f0fcf9bf1b1f4dc7b5c57aab0c0aa5ae","execution_count":30,"outputs":[{"name":"stdout","text":"First Dense Layer Weights Shape: (300, 256)\nFirst Dense Layer Biases Shape: (256,)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/f1daa676-190e-45e6-a309-40477b3879ad","content_dependencies":null},{"cell_type":"code","metadata":{"deepnote_to_be_reexecuted":true,"cell_id":"d85f6769e8794043a42b5a0c4b81cf2f","deepnote_cell_type":"code"},"source":"","block_group":"887ae2a58c5047b6a4da97a7d05a64c5","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=032938a2-8262-4fbb-9ab0-ef927092c39b' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"0d0510226cce4288878ce443e6d28ac6"}}